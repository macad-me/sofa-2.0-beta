name: 🚀 Direct SOFA Pipeline (Bypass Python Script)

on:
  workflow_dispatch:
    inputs:
      commit_results:
        description: 'Commit generated data'
        type: boolean
        default: true
  schedule:
    # Run every 4 hours
    - cron: '0 */4 * * *'

jobs:
  direct-pipeline:
    name: Direct Binary Pipeline
    runs-on: ubuntu-latest
    
    steps:
      - name: Setup processing directory
        run: |
          echo "🏗️ Setting up processing environment..."
          
          # Create processing directory
          mkdir -p processing
          cd processing
          
          echo "📍 Current location: $(pwd)"
          echo "📊 Directory contents:"
          ls -la
          
      - name: Checkout repository to processing folder
        uses: actions/checkout@v4
        with:
          path: processing
          
      - name: Verify repository structure
        run: |
          echo "📊 Processing directory after checkout:"
          cd processing
          pwd
          ls -la
          
          echo "📊 Key directories:"
          ls -la config/ data/ || echo "Missing directories"
          
          echo "📊 Existing beta data:"
          if [ -f "data/resources/apple_beta_feed.json" ]; then
            echo "✅ apple_beta_feed.json exists ($(wc -c < data/resources/apple_beta_feed.json) bytes)"
            echo "   Modified: $(stat -c %Y data/resources/apple_beta_feed.json) ($(date -d @$(stat -c %Y data/resources/apple_beta_feed.json)))"
          else
            echo "❌ apple_beta_feed.json missing"
          fi
          
      - name: Install system requirements
        run: |
          echo "🔧 Installing system requirements..."
          
          # Install tools
          sudo apt-get update
          sudo apt-get install -y ca-certificates curl jq
          
          # Install Apple root certificates
          echo "🔐 Installing Apple root certificates..."
          sudo curl -f -o /usr/local/share/ca-certificates/apple-root-ca-g3.crt \
            "https://www.apple.com/certificateauthority/AppleRootCA-G3.cer"
          sudo curl -f -o /usr/local/share/ca-certificates/apple-root-ca.crt \
            "https://www.apple.com/certificateauthority/AppleComputerRootCertificate.cer"
          sudo update-ca-certificates
          
          echo "✅ System setup complete"
          
      - name: Download latest SOFA binaries v0.1.1-beta1
        run: |
          echo "📥 Downloading SOFA CLI v0.1.1-beta1 binaries..."
          cd processing
          mkdir -p bin
          
          DOWNLOAD_URL="https://github.com/headmin/sofa-core-cli/releases/download/v0.1.1-beta1"
          LINUX_ZIP="sofa-core-cli-x86_64-linux-binaries.zip"
          
          echo "Downloading: $DOWNLOAD_URL/$LINUX_ZIP"
          curl -L -f -o "$LINUX_ZIP" "$DOWNLOAD_URL/$LINUX_ZIP"
          unzip -o -j "$LINUX_ZIP" -d bin/
          chmod +x bin/*
          rm "$LINUX_ZIP"
          
          echo "📊 Downloaded binaries:"
          ls -la bin/
          
          echo "✅ Testing binaries:"
          ./bin/sofa-gather --version
          ./bin/sofa-fetch --version  
          ./bin/sofa-build --version
          
      - name: Fix gather.toml configuration
        run: |
          echo "🔧 Configuring gather.toml with absolute paths..."
          cd processing
          
          PROC_DIR=$(pwd)
          echo "📍 Processing directory: $PROC_DIR"
          
          # Backup and modify gather.toml
          if [ -f "config/gather.toml" ]; then
            cp config/gather.toml config/gather.toml.backup
            
            # Fix paths to absolute
            sed "s|directory = \"../data/resources\"|directory = \"$PROC_DIR/data/resources\"|g" config/gather.toml.backup | \
            sed "s|directory = \"../data/cache\"|directory = \"$PROC_DIR/data/cache\"|g" > config/gather.toml
            
            echo "✅ Modified gather.toml:"
            cat config/gather.toml
          else
            echo "❌ No gather.toml found"
            exit 1
          fi
          
      - name: STAGE 1 - Gather all data sources
        run: |
          echo "🎯 STAGE 1: GATHER - Collecting all data sources..."
          cd processing
          
          echo "📍 Working from: $(pwd)"
          echo "📊 Before gather - data/resources:"
          ls -la data/resources/ || mkdir -p data/resources
          
          # Create necessary directories
          mkdir -p data/resources data/cache logs
          
          echo "🚀 Running: ./bin/sofa-gather all --continue-on-error"
          export RUST_LOG=info
          
          BEFORE_TIME=$(date +%s)
          
          if timeout 300 ./bin/sofa-gather all --continue-on-error 2>&1 | tee logs/gather.log; then
            echo "✅ Gather completed successfully"
            
            echo "📊 After gather - data/resources:"
            ls -la data/resources/
            
            echo "📊 Files created/modified during gather:"
            find data/resources -name "*.json" -newermt "@$BEFORE_TIME" -ls || echo "No new files"
            
            # Check beta files specifically
            if [ -f "data/resources/apple_beta_feed.json" ]; then
              echo "✅ apple_beta_feed.json: $(wc -c < data/resources/apple_beta_feed.json) bytes"
              echo "   Items: $(jq -r '.items | length' data/resources/apple_beta_feed.json 2>/dev/null)"
              echo "   Created: $(jq -r '.created_at' data/resources/apple_beta_feed.json 2>/dev/null)"
            fi
          else
            echo "❌ Gather failed"
            echo "📋 Gather log (last 20 lines):"
            tail -20 logs/gather.log || echo "No log"
            exit 1
          fi
          
      - name: STAGE 2 - Fetch Apple security data
        run: |
          echo "🎯 STAGE 2: FETCH - Processing Apple security releases..."
          cd processing
          
          echo "📍 Working from: $(pwd)"
          echo "📊 Required input files:"
          ls -la data/resources/kev_catalog.json || echo "❌ KEV missing"
          
          echo "🚀 Running: ./bin/sofa-fetch"
          
          # Run sofa-fetch with proper paths
          if timeout 300 ./bin/sofa-fetch \
            --output "data/resources/apple_security_releases.json" \
            --kev-file "data/resources/kev_catalog.json" \
            --cache-dir "data/cache/html" \
            --preserve-html 2>&1 | tee logs/fetch.log; then
            
            echo "✅ Fetch completed successfully"
            
            echo "📊 Fetch results:"
            if [ -f "data/resources/apple_security_releases.json" ]; then
              RELEASES=$(jq -r '.releases | length' data/resources/apple_security_releases.json 2>/dev/null)
              echo "✅ apple_security_releases.json: $(wc -c < data/resources/apple_security_releases.json) bytes, $RELEASES releases"
            else
              echo "❌ apple_security_releases.json missing"
              exit 1
            fi
          else
            echo "❌ Fetch failed"
            echo "📋 Fetch log (last 20 lines):"
            tail -20 logs/fetch.log || echo "No log"
            exit 1
          fi
          
      - name: STAGE 3 - Build v1 and v2 feeds
        run: |
          echo "🎯 STAGE 3: BUILD - Generating v1 and v2 feeds..."
          cd processing
          
          echo "📍 Working from: $(pwd)"
          echo "📊 Input data for build:"
          ls -la data/resources/*.json | head -10
          
          # Create feed directories
          mkdir -p data/feeds/v1 data/feeds/v2
          
          # Products to build
          PRODUCTS=("safari" "ios" "macos" "tvos" "watchos" "visionos")
          
          echo "🔧 Building v1 feeds..."
          for product in "${PRODUCTS[@]}"; do
            echo "  Building $product v1..."
            if timeout 120 ./bin/sofa-build "$product" \
              -i "data/resources" \
              -f "data/feeds/v1/${product}_data_feed.json" \
              --type "v1" 2>&1 | tee "logs/build_v1_${product}.log"; then
              echo "  ✅ $product v1 completed"
            else
              echo "  ❌ $product v1 failed"
            fi
          done
          
          echo "🔧 Building v2 feeds..."
          for product in "${PRODUCTS[@]}"; do
            echo "  Building $product v2..."
            if timeout 120 ./bin/sofa-build "$product" \
              -i "data/resources" \
              -f "data/feeds/v2/${product}_data_feed.json" \
              --type "v2" 2>&1 | tee "logs/build_v2_${product}.log"; then
              echo "  ✅ $product v2 completed"
            else
              echo "  ❌ $product v2 failed"
            fi
          done
          
          echo "📊 Build results:"
          echo "v1 feeds:"
          ls -la data/feeds/v1/ || echo "No v1 feeds"
          echo "v2 feeds:"
          ls -la data/feeds/v2/ || echo "No v2 feeds"
          
      - name: Generate bulletin and RSS
        run: |
          echo "🎯 STAGE 4: BULLETIN & RSS - Final data generation..."
          cd processing
          
          echo "🔧 Generating bulletin data..."
          if timeout 60 ./bin/sofa-build bulletin \
            -i "data/resources" \
            -b "data/resources/bulletin_data.json" 2>&1 | tee logs/bulletin.log; then
            echo "✅ Bulletin generated"
            if [ -f "data/resources/bulletin_data.json" ]; then
              echo "   Size: $(wc -c < data/resources/bulletin_data.json) bytes"
            fi
          else
            echo "❌ Bulletin generation failed"
          fi
          
          echo "📊 Final data structure:"
          echo "Resources:"
          ls -la data/resources/ | head -15
          echo "Feeds v1:"
          ls -la data/feeds/v1/ | head -10
          echo "Feeds v2:"  
          ls -la data/feeds/v2/ | head -10
          
      - name: Commit generated data
        if: github.event.inputs.commit_results == 'true' || github.event_name == 'schedule'
        run: |
          echo "📝 Committing generated data..."
          cd processing
          
          # Configure git
          git config --local user.email "action@github.com"
          git config --local user.name "Direct Pipeline"
          
          # Add all generated data
          git add data/resources/ data/feeds/
          
          if git diff --staged --quiet; then
            echo "ℹ️ No changes to commit"
          else
            echo "📝 Changes detected:"
            git diff --staged --name-only
            
            TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M UTC")
            git commit -m "🚀 Direct pipeline data update - $TIMESTAMP

            Generated using direct binary calls (bypassing Python script):
            - sofa-gather all: Fresh data collection
            - sofa-fetch: Apple security releases processing  
            - sofa-build: v1 and v2 feed generation
            
            Updated feeds and resources with latest data."
            
            git push
            echo "✅ Data committed and pushed"
          fi
          
      - name: Pipeline summary
        if: always()
        run: |
          echo "## 🚀 Direct Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          cd processing
          
          echo "### 📊 Generated Data" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check beta data
          if [ -f "data/resources/apple_beta_feed.json" ]; then
            SIZE=$(wc -c < data/resources/apple_beta_feed.json)
            ITEMS=$(jq -r '.items | length' data/resources/apple_beta_feed.json 2>/dev/null)
            CREATED=$(jq -r '.created_at' data/resources/apple_beta_feed.json 2>/dev/null)
            echo "- **Beta Feed**: ✅ $SIZE bytes, $ITEMS items" >> $GITHUB_STEP_SUMMARY
            echo "- **Created**: $CREATED" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **Beta Feed**: ❌ Missing" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Check security releases
          if [ -f "data/resources/apple_security_releases.json" ]; then
            SIZE=$(wc -c < data/resources/apple_security_releases.json)
            RELEASES=$(jq -r '.releases | length' data/resources/apple_security_releases.json 2>/dev/null)
            echo "- **Security Releases**: ✅ $SIZE bytes, $RELEASES releases" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **Security Releases**: ❌ Missing" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Check feeds
          V1_COUNT=$(ls data/feeds/v1/*.json 2>/dev/null | wc -l)
          V2_COUNT=$(ls data/feeds/v2/*.json 2>/dev/null | wc -l)
          echo "- **v1 Feeds**: $V1_COUNT files" >> $GITHUB_STEP_SUMMARY
          echo "- **v2 Feeds**: $V2_COUNT files" >> $GITHUB_STEP_SUMMARY
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🎯 Status" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "data/resources/apple_beta_feed.json" ] && [ -f "data/resources/apple_security_releases.json" ] && [ "$V1_COUNT" -gt 0 ] && [ "$V2_COUNT" -gt 0 ]; then
            echo "✅ **SUCCESS**: All pipeline stages completed successfully!" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **PARTIAL**: Some pipeline stages failed - check logs" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: direct-pipeline-${{ github.run_number }}
          path: |
            processing/logs/
            processing/data/resources/
            processing/data/feeds/
          retention-days: 7
          if-no-files-found: warn