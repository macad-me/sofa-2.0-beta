name: 🧪 Run base SOFA Pipeline v0.1.1

on:
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
    inputs:
      test_stage:
        description: 'Which stage to test'
        type: choice
        default: 'all'
        options:
        - gather
        - fetch
        - build
        - all
      debug_mode:
        description: 'Enable verbose debugging'
        type: boolean
        default: true
      fast_track:
        description: '⚡ Schedule another run in 5 minutes (for testing)'
        type: boolean
        default: false
  schedule:
    # Monday, Tuesday, Thursday, and Friday every 1 hour from 5:00 PM to 8:00 PM CET
    - cron: '0 17-20 * * 1,2,3,4,5'

    # On every day every 4 hours
    - cron: '30 */4 * * *'
env:
  PYTHON_VERSION: '3.13'

jobs:
  test-pipeline:
    name: Force Test Pipeline
    runs-on: ubuntu-latest
    
    steps:
      - name: Setup processing directory
        run: |
          echo "🏗️ Setting up processing environment..."
          mkdir -p processing
          
      - name: Checkout repository to processing folder
        uses: actions/checkout@v4
        with:
          path: processing
        
      - name: Show environment info
        run: |
          echo "## 🧪 Pipeline Test Environment" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**OS:** $(lsb_release -d | cut -f2)" >> $GITHUB_STEP_SUMMARY
          echo "**Architecture:** $(uname -m)" >> $GITHUB_STEP_SUMMARY
          echo "**Kernel:** $(uname -r)" >> $GITHUB_STEP_SUMMARY
          echo "**Python:** $(python3 --version)" >> $GITHUB_STEP_SUMMARY
          echo "**Test Stage:** ${{ github.event.inputs.test_stage }}" >> $GITHUB_STEP_SUMMARY
          echo "**Debug Mode:** ${{ github.event.inputs.debug_mode }}" >> $GITHUB_STEP_SUMMARY
          echo "**Timestamp:** $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Show architecture details
          echo "🖥️ Runner Architecture Details:"
          uname -a
          lscpu | head -5 || echo "lscpu not available"
          
          echo "📍 Working from processing directory:"
          cd processing
          pwd
          ls -la
          
      - name: Install Apple Root Certificates
        run: |
          echo "🔐 Installing Apple root certificates for SSL validation..."
          
          # Update package database
          sudo apt-get update
          
          # Install ca-certificates if not present
          sudo apt-get install -y ca-certificates curl
          
          # Download and install Apple Root CA-G3 (current primary root)
          echo "📥 Downloading Apple Root CA-G3..."
          sudo curl -f -o /usr/local/share/ca-certificates/apple-root-ca-g3.crt \
            "https://www.apple.com/certificateauthority/AppleRootCA-G3.cer"
          
          # Download and install Apple Root CA (legacy support)
          echo "📥 Downloading Apple Root CA (legacy)..."
          sudo curl -f -o /usr/local/share/ca-certificates/apple-root-ca.crt \
            "https://www.apple.com/certificateauthority/AppleComputerRootCertificate.cer"
          
          # Update system certificate store
          echo "🔄 Updating system certificate store..."
          sudo update-ca-certificates
          
          # Verify installation
          echo "✅ Apple certificates installed:"
          ls -la /usr/local/share/ca-certificates/apple-*
          
          # Test SSL connection to Apple Developer
          echo "🧪 Testing SSL connection to developer.apple.com..."
          if curl -I --max-time 10 "https://developer.apple.com/news/releases/" >/dev/null 2>&1; then
            echo "✅ SSL connection to Apple Developer successful"
          else
            echo "⚠️ SSL connection test failed - but continuing anyway"
          fi
          
      - name: Download SOFA CLI binaries
        run: |
          echo "📥 Downloading latest SOFA CLI binaries..."
          cd processing
          mkdir -p bin

          # Use specific version since latest release is marked as prerelease
          DOWNLOAD_URL="https://github.com/headmin/sofa-core-cli/releases/download/v0.1.1-beta1"
          LINUX_ZIP="sofa-core-cli-x86_64-linux-binaries.zip"

          echo "  • Downloading Linux binaries: $LINUX_ZIP"
          if curl -L -f -o "$LINUX_ZIP" "$DOWNLOAD_URL/$LINUX_ZIP"; then
            echo "    ✅ Downloaded: $LINUX_ZIP"

            echo "  • Extracting binaries..."
            unzip -o -j "$LINUX_ZIP" -d bin/
            chmod +x bin/*
            rm "$LINUX_ZIP"

            echo "    ✅ Extracted and made executable"
            echo "  • Extracted files:"
            ls -la bin/
          else
            echo "    ❌ Failed to download: $LINUX_ZIP"
            exit 1
          fi


          
      - name: Test binary execution
        run: |
          echo "🧪 Testing essential SOFA CLI binaries..."
          cd processing/bin
          
          # Only test the binaries we actually need for the pipeline
          ESSENTIAL_BINARIES=("sofa-build" "sofa-cve" "sofa-fetch" "sofa-gather")
          
          for binary in "${ESSENTIAL_BINARIES[@]}"; do
            echo "Testing $binary..."
            
            # Check if binary exists and is executable
            if [ ! -f "$binary" ]; then
              echo "  ❌ $binary not found"
              continue
            fi
            
            if [ ! -x "$binary" ]; then
              echo "  ❌ $binary not executable"
              continue  
            fi
            
            # Check binary architecture
            echo "  🔍 Binary info: $(file "$binary")"
            
            # Test execution
            if ./"$binary" --version 2>&1; then
              echo "  ✅ $binary works"
            else
              EXITCODE=$?
              echo "  ❌ $binary failed (exit code: $EXITCODE)"
              echo "  🔍 Checking binary dependencies..."
              ldd "$binary" 2>/dev/null | head -3 || echo "  Static binary (no dependencies)"
              echo "## ❌ Binary Test Failed" >> $GITHUB_STEP_SUMMARY
              echo "Essential binary \`$binary\` failed with exit code $EXITCODE" >> $GITHUB_STEP_SUMMARY
              exit 1
            fi
          done
          
          # Remove any non-essential binaries that were extracted
          echo "🧹 Cleaning up non-essential binaries..."
          rm -f sofa-init 2>/dev/null || true
          ls -la
          
      - name: Set up Python and UV
        run: |
          echo "🐍 Setting up Python environment..."
          python3 --version
          
          echo "📦 Installing UV..."
          curl -LsSf https://astral.sh/uv/install.sh | sh
          
          # UV installs to ~/.local/bin
          export PATH="$HOME/.local/bin:$PATH"
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          
          # Verify UV installation
          echo "🔍 Checking UV installation..."
          echo "UV install directory contents:"
          ls -la $HOME/.local/bin/ | grep uv || echo "UV not found in .local/bin"
          
          # Test UV directly with full path
          echo "Testing UV with full path:"
          $HOME/.local/bin/uv --version
          
          # Test UV via PATH
          echo "Testing UV via PATH:"
          which uv
          uv --version


          
      - name: Test gather stage
        if: github.event_name == 'schedule' || contains(github.event.inputs.test_stage, 'gather') || github.event.inputs.test_stage == 'all'
        run: |
          echo "📊 Testing GATHER stage..."
          cd processing
          
          echo "📍 Working from processing directory: $(pwd)"
          echo "📊 Directory structure:"
          ls -la
          
          # Setup environment for processing folder
          export SOFA_BIN_PATH="./bin"
          export PATH="./bin:$HOME/.local/bin:$PATH"
          
          # Directory paths are now relative to processing folder (no absolute paths needed!)
          mkdir -p data/resources data/cache logs
          
          echo "📊 Before gather - existing data:"
          ls -la data/resources/ || echo "No resources directory"
          
          # Use the clean, simple pipeline script  
          echo "Running: uv run --script scripts/sofa_pipeline_clean.py run gather"
          if uv run --script scripts/sofa_pipeline_clean.py run gather; then
            echo "✅ Pipeline GATHER stage completed"
            echo "## ✅ Gather Stage Success" >> $GITHUB_STEP_SUMMARY
            
            echo ""
            echo "🔍 Verifying gathered data files..."
            if ./scripts/verify_gathered_data.sh; then
              echo "✅ All gathered data verified successfully"
              echo "## ✅ Data Verification Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "⚠️ Some data verification issues found (see logs above)"
              echo "## ⚠️ Data Verification Issues" >> $GITHUB_STEP_SUMMARY
            fi
            
            echo ""
            echo "🍎 Beta Files Validation..."
            echo "## 📊 Beta Data Status" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Check beta feed file
            if [ -f "data/resources/apple_beta_feed.json" ]; then
              FEED_SIZE=$(stat -c%s "data/resources/apple_beta_feed.json" 2>/dev/null || stat -f%z "data/resources/apple_beta_feed.json" 2>/dev/null)
              FEED_MTIME=$(stat -c%Y "data/resources/apple_beta_feed.json" 2>/dev/null || stat -f%m "data/resources/apple_beta_feed.json" 2>/dev/null)
              FEED_AGE=$(($(date +%s) - FEED_MTIME))
              FEED_AGE_HOURS=$((FEED_AGE / 3600))
              
              echo "✅ apple_beta_feed.json: ${FEED_SIZE} bytes, ${FEED_AGE_HOURS}h old"
              echo "- **apple_beta_feed.json**: ✅ ${FEED_SIZE} bytes, ${FEED_AGE_HOURS}h old" >> $GITHUB_STEP_SUMMARY
              
              # Validate JSON structure
              if BETA_COUNT=$(jq -r '.items | length' "data/resources/apple_beta_feed.json" 2>/dev/null); then
                FEED_HASH=$(jq -r '.UpdateHash // "unknown"' "data/resources/apple_beta_feed.json" 2>/dev/null)
                echo "  📊 Contains ${BETA_COUNT} beta releases, hash: ${FEED_HASH:0:16}..."
                echo "  - Contains **${BETA_COUNT}** beta releases" >> $GITHUB_STEP_SUMMARY
                echo "  - Hash: \`${FEED_HASH:0:16}...\`" >> $GITHUB_STEP_SUMMARY
              else
                echo "  ❌ Invalid JSON structure"
                echo "  - ❌ **Invalid JSON structure**" >> $GITHUB_STEP_SUMMARY
              fi
            else
              echo "❌ apple_beta_feed.json: NOT FOUND"
              echo "- **apple_beta_feed.json**: ❌ NOT FOUND" >> $GITHUB_STEP_SUMMARY
            fi
            
            # Check beta history file
            if [ -f "data/resources/apple_beta_os_history.json" ]; then
              HISTORY_SIZE=$(stat -c%s "data/resources/apple_beta_os_history.json" 2>/dev/null || stat -f%z "data/resources/apple_beta_os_history.json" 2>/dev/null)
              HISTORY_MTIME=$(stat -c%Y "data/resources/apple_beta_os_history.json" 2>/dev/null || stat -f%m "data/resources/apple_beta_os_history.json" 2>/dev/null)
              HISTORY_AGE=$(($(date +%s) - HISTORY_MTIME))
              HISTORY_AGE_HOURS=$((HISTORY_AGE / 3600))
              
              echo "✅ apple_beta_os_history.json: ${HISTORY_SIZE} bytes, ${HISTORY_AGE_HOURS}h old"
              echo "- **apple_beta_os_history.json**: ✅ ${HISTORY_SIZE} bytes, ${HISTORY_AGE_HOURS}h old" >> $GITHUB_STEP_SUMMARY
              
              # Validate JSON structure
              if HISTORY_COUNT=$(jq -r 'length' "data/resources/apple_beta_os_history.json" 2>/dev/null); then
                echo "  📊 Contains ${HISTORY_COUNT} historical beta entries"
                echo "  - Contains **${HISTORY_COUNT}** historical beta entries" >> $GITHUB_STEP_SUMMARY
              else
                echo "  ❌ Invalid JSON structure"
                echo "  - ❌ **Invalid JSON structure**" >> $GITHUB_STEP_SUMMARY
              fi
            else
              echo "❌ apple_beta_os_history.json: NOT FOUND"
              echo "- **apple_beta_os_history.json**: ❌ NOT FOUND" >> $GITHUB_STEP_SUMMARY
            fi
            
            # Test direct beta gathering with new binary
            echo ""
            echo "🧪 Testing direct beta gathering with beta3 binary..."
            export RUST_LOG=info
            BETA_TEST_OUTPUT="/tmp/beta_test_$(date +%s).json"
            
            if timeout 120 ./bin/sofa-gather beta --output "$BETA_TEST_OUTPUT" 2>&1 | tee logs/beta_gather_test.log; then
              if [ -f "$BETA_TEST_OUTPUT" ]; then
                TEST_SIZE=$(stat -c%s "$BETA_TEST_OUTPUT" 2>/dev/null || stat -f%z "$BETA_TEST_OUTPUT" 2>/dev/null)
                TEST_COUNT=$(jq -r '.items | length' "$BETA_TEST_OUTPUT" 2>/dev/null || echo "parse_error")
                echo "✅ Direct beta gathering successful: ${TEST_SIZE} bytes, ${TEST_COUNT} items"
                echo "- **Direct beta3 test**: ✅ ${TEST_SIZE} bytes, ${TEST_COUNT} items" >> $GITHUB_STEP_SUMMARY
                
                # Compare with existing file
                if [ -f "data/resources/apple_beta_feed.json" ]; then
                  if cmp -s "$BETA_TEST_OUTPUT" "data/resources/apple_beta_feed.json"; then
                    echo "  📋 Content identical to existing file"
                    echo "  - Content matches existing file" >> $GITHUB_STEP_SUMMARY
                  else
                    echo "  🔄 Content differs from existing file - new data available"
                    echo "  - **🔄 New beta data available**" >> $GITHUB_STEP_SUMMARY
                    # Replace existing file with fresh data
                    cp "$BETA_TEST_OUTPUT" "data/resources/apple_beta_feed.json"
                    echo "  ✅ Updated apple_beta_feed.json with fresh data"
                    echo "  - Updated apple_beta_feed.json with fresh data" >> $GITHUB_STEP_SUMMARY
                  fi
                fi
                
                rm -f "$BETA_TEST_OUTPUT"
              else
                echo "❌ Direct beta gathering produced no output file"
                echo "- **Direct beta3 test**: ❌ No output file" >> $GITHUB_STEP_SUMMARY
              fi
            else
              echo "❌ Direct beta gathering failed or timed out"
              echo "- **Direct beta3 test**: ❌ Failed or timed out" >> $GITHUB_STEP_SUMMARY
              if [ -f "logs/beta_gather_test.log" ]; then
                echo "Error log:"
                tail -10 "logs/beta_gather_test.log"
              fi
            fi
            
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ GATHER stage failed"
            echo "## ❌ Gather Stage Failed" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
          
      - name: Test fetch stage
        if: github.event_name == 'schedule' || contains(github.event.inputs.test_stage, 'fetch') || github.event.inputs.test_stage == 'all'
        run: |
          echo "🔍 Testing FETCH stage..."
          cd processing

          export SOFA_BIN_PATH="./bin"
          export PATH="./bin:$HOME/.local/bin:$PATH"

          echo "Running: uv run --script scripts/sofa_pipeline_clean.py run fetch"
          if uv run --script scripts/sofa_pipeline_clean.py run fetch; then
            echo "✅ FETCH stage completed"
            echo "## ✅ Fetch Stage Success" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ FETCH stage failed"
            echo "## ❌ Fetch Stage Failed" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
          




      - name: Test build stage
        if: github.event_name == 'schedule' || contains(github.event.inputs.test_stage, 'build') || github.event.inputs.test_stage == 'all'
        run: |
          echo "🔨 Testing BUILD stage..."
          cd processing

          # Ensure supported_devices.json is in both required locations
          if [ -f "data/models/supported_devices.json" ]; then
            cp data/models/supported_devices.json data/resources/
          fi
          mkdir -p data/models
          if [ -f "data/resources/supported_devices.json" ]; then
            cp data/resources/supported_devices.json data/models/
          fi

          export SOFA_BIN_PATH="./bin"
          export PATH="./bin:$HOME/.local/bin:$PATH"

          echo "Running: uv run --script scripts/sofa_pipeline_clean.py run build"
          if uv run --script scripts/sofa_pipeline_clean.py run build; then
            echo "✅ BUILD stage completed"
            echo "## ✅ Build Stage Success" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ BUILD stage failed"
            echo "## ❌ Build Stage Failed" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
          
      - name: Show generated files
        if: success() && (github.event_name == 'schedule' || contains(github.event.inputs.test_stage, 'build') || github.event.inputs.test_stage == 'all')
        run: |
          echo "📁 Checking generated files..."
          echo "## 📁 Generated Files" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -d "data/feeds" ]; then
            echo "### Feeds Directory:" >> $GITHUB_STEP_SUMMARY
            find data/feeds -type f | head -20 | while read file; do
              size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null || echo "unknown")
              echo "- \`$file\` (${size} bytes)" >> $GITHUB_STEP_SUMMARY
            done
          else
            echo "❌ No data/feeds directory found" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -d "data/resources" ]; then
            echo "### Resources Directory:" >> $GITHUB_STEP_SUMMARY
            find data/resources -type f | head -20 | while read file; do
              size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null || echo "unknown")
              echo "- \`$file\` (${size} bytes)" >> $GITHUB_STEP_SUMMARY
            done
          else
            echo "❌ No data/resources directory found" >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Test RSS generation with beta validation
        if: success() && (github.event_name == 'schedule' || contains(github.event.inputs.test_stage, 'build') || github.event.inputs.test_stage == 'all')
        run: |
          echo "📡 Testing RSS generation with beta validation..."
          cd processing
          
          # Check for required input files
          echo "📊 RSS input files:"
          ls -la data/resources/bulletin_data.json || echo "❌ bulletin_data.json missing"
          ls -la data/resources/apple_beta_feed.json || echo "❌ apple_beta_feed.json missing" 
          
          if [ -f "data/resources/bulletin_data.json" ]; then
            echo "✅ Found bulletin_data.json, generating RSS with beta inclusion..."
            
            # Generate RSS with beta releases included for validation
            if uv run --script scripts/generate_rss.py \
              --data-dir data/resources \
              --output data/feeds/v1/rss_feed.xml \
              --include-xprotect \
              --include-beta \
              --verbose; then
              
              echo "✅ RSS generation completed"
              echo "## ✅ RSS Generation Success" >> $GITHUB_STEP_SUMMARY
              
              if [ -f "data/feeds/v1/rss_feed.xml" ]; then
                rss_size=$(stat -f%z "data/feeds/v1/rss_feed.xml" 2>/dev/null || stat -c%s "data/feeds/v1/rss_feed.xml" 2>/dev/null)
                echo "Generated RSS feed: ${rss_size} bytes" >> $GITHUB_STEP_SUMMARY
                
                # VALIDATE BETA CONTENT IN RSS
                echo ""
                echo "🔍 Validating beta content in RSS feed..."
                
                if grep -q "beta 9" data/feeds/v1/rss_feed.xml; then
                  echo "✅ Found beta 9 releases in RSS feed"
                  echo "- **Beta 9 Validation**: ✅ Found in RSS feed" >> $GITHUB_STEP_SUMMARY
                  
                  # Show specific beta entries
                  echo "📊 Beta entries in RSS:"
                  grep -A2 -B2 "beta 9" data/feeds/v1/rss_feed.xml || echo "Could not extract beta entries"
                else
                  echo "❌ Beta 9 releases NOT found in RSS feed"
                  echo "- **Beta 9 Validation**: ❌ Missing from RSS feed" >> $GITHUB_STEP_SUMMARY
                  
                  # Check what betas are actually in the RSS
                  echo "🔍 Beta content in RSS:"
                  grep -i "beta" data/feeds/v1/rss_feed.xml | head -5 || echo "No beta content found"
                fi
                
                # Check total item count in RSS
                RSS_ITEMS=$(grep -c "<item>" data/feeds/v1/rss_feed.xml || echo "0")
                echo "📊 Total RSS items: $RSS_ITEMS"
                echo "- **Total RSS Items**: $RSS_ITEMS" >> $GITHUB_STEP_SUMMARY
              fi
            else
              echo "❌ RSS generation failed"
              echo "## ❌ RSS Generation Failed" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "⚠️ No bulletin_data.json found, skipping RSS test"
            echo "## ⚠️ RSS Test Skipped" >> $GITHUB_STEP_SUMMARY
            echo "No bulletin_data.json found for RSS generation" >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Commit test results to repo
        if: github.event_name == 'schedule' || github.event.inputs.test_stage == 'all' || github.event.inputs.test_stage == 'build'
        run: |
          echo "💾 Committing generated data back to repository..."
          cd processing
          
          # Show what data was generated
          echo "🔍 Generated data structure:"
          find data/ -type f | head -20 || echo "No data files found"
          
          # Add generated data
          git config --local user.email "test@github.com"
          git config --local user.name "Pipeline Test"
          
          # Explicitly add EVERY resource file (based on successful test run)
          echo "📁 Adding ALL expected resource files explicitly:"
          git add data/resources/apple_beta_feed.json && echo "✅ Added apple_beta_feed.json" || echo "❌ apple_beta_feed.json not found or unchanged"
          git add data/resources/apple_beta_os_history.json && echo "✅ Added apple_beta_os_history.json" || echo "❌ apple_beta_os_history.json not found or unchanged"
          git add data/resources/apple_cves_with_context.ndjson && echo "✅ Added apple_cves_with_context.ndjson" || echo "❌ apple_cves_with_context.ndjson not found or unchanged"
          git add data/resources/apple_security_releases.json && echo "✅ Added apple_security_releases.json" || echo "❌ apple_security_releases.json not found or unchanged"
          git add data/resources/apple_security_releases.ndjson && echo "✅ Added apple_security_releases.ndjson" || echo "❌ apple_security_releases.ndjson not found or unchanged"
          git add data/resources/gdmf_history.ndjson && echo "✅ Added gdmf_history.ndjson" || echo "❌ gdmf_history.ndjson not found or unchanged"
          git add data/resources/gdmf_cached.json && echo "✅ Added gdmf_cached.json" || echo "❌ gdmf_cached.json not found or unchanged"
          git add data/resources/gdmf_log.json && echo "✅ Added gdmf_log.json" || echo "❌ gdmf_log.json not found or unchanged"
          git add data/resources/ipsw.json && echo "✅ Added ipsw.json" || echo "❌ ipsw.json not found or unchanged"
          git add data/resources/kev_catalog.json && echo "✅ Added kev_catalog.json" || echo "❌ kev_catalog.json not found or unchanged"
          git add data/resources/mac_models_mapping.json && echo "✅ Added mac_models_mapping.json" || echo "❌ mac_models_mapping.json not found or unchanged"
          git add data/resources/sofa-status.json && echo "✅ Added sofa-status.json" || echo "❌ sofa-status.json not found or unchanged"
          git add data/resources/uma_catalog.json && echo "✅ Added uma_catalog.json" || echo "❌ uma_catalog.json not found or unchanged"
          git add data/resources/xprotect.json && echo "✅ Added xprotect.json" || echo "❌ xprotect.json not found or unchanged"
          
          # Add all feeds and other resources  
          git add data/feeds/ && echo "✅ Added feeds directory" || echo "❌ feeds directory not found or unchanged"
          git add data/resources/ && echo "✅ Added remaining resources" || echo "❌ resources directory not found or unchanged"
          
          if git diff --staged --quiet; then
            echo "📝 No new data to commit"
          else
            echo "📝 Committing generated pipeline data..."
            git commit -m "Update SOFA data from test pipeline run

            - Generated from test workflow execution
            - Pipeline stage: ${{ github.event.inputs.test_stage }}
            - Test timestamp: $(date -u)
            - Updated feeds and resources with latest data"
            
            git push
            echo "✅ Pipeline data committed to repository"
          fi
          
      - name: Upload debug artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-debug-${{ github.run_number }}
          path: |
            processing/logs/
            processing/data/resources/
            processing/data/feeds/
          retention-days: 7
          if-no-files-found: warn
          
      - name: Final summary
        if: always()
        run: |
          echo "## 🎯 Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Test Stage:** ${{ github.event.inputs.test_stage }}" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "**Completed:** $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check the step logs above to see exactly where the pipeline succeeded or failed." >> $GITHUB_STEP_SUMMARY

      - name: Schedule fast track run
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.fast_track == 'true'
        run: |
          echo "⚡ Fast track requested - will trigger another run in 5 minutes..."

          FUTURE_TIME=$(date -u -d '+5 minutes' '+%Y-%m-%d %H:%M:%S UTC')
          echo "Next run scheduled for: $FUTURE_TIME"

          echo "## ⚡ Fast Track Scheduled" >> $GITHUB_STEP_SUMMARY
          echo "Another base pipeline run will start in **5 minutes** at $FUTURE_TIME" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The fast track run will:" >> $GITHUB_STEP_SUMMARY
          echo "- Run the same test stage: **${{ github.event.inputs.test_stage }}**" >> $GITHUB_STEP_SUMMARY
          echo "- Enable debug mode" >> $GITHUB_STEP_SUMMARY
          echo "- Execute all pipeline steps" >> $GITHUB_STEP_SUMMARY

          # Start background job that waits 5 minutes then triggers workflow
          (
            echo "⏰ Waiting 5 minutes before triggering fast track run..."
            sleep 300  # 5 minutes

            echo "🚀 Triggering fast track base pipeline run..."
            curl -X POST \
              -H "Accept: application/vnd.github.v3+json" \
              -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              -H "X-GitHub-Api-Version: 2022-11-28" \
              https://api.github.com/repos/${{ github.repository }}/actions/workflows/run-base-pipeline.yml/dispatches \
              -d '{
                "ref": "main",
                "inputs": {
                  "test_stage": "${{ github.event.inputs.test_stage }}",
                  "debug_mode": "true",
                  "fast_track": "false"
                }
              }'

            echo "✅ Fast track run triggered successfully"
          ) &

          echo "🔄 Background job started - this workflow will complete while the timer runs"
